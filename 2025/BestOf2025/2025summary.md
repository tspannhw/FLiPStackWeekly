# **Timothy Spann in 2025: The Architect of the Agentic Data Era**

## **1\. Introduction: The Convergence of Streams and Sentience**

The year 2025 represented a watershed moment in the discipline of data engineering, characterized by the collapse of the traditional barriers between deterministic data processing and probabilistic artificial intelligence. At the epicenter of this seismic shift stood Timothy Spann, a veteran technologist whose professional trajectory throughout the year served as a microcosm for the industry’s broader evolution. Operating at the intersection of streaming ingestion, open table formats, and generative AI, Spann’s activities in 2025 were not merely a continuation of his previous advocacy for "Big Data" but rather a radical redefinition of what it means to be a data practitioner in the age of autonomous agents.

As a Senior Solutions Engineer at Snowflake and a prolific contributor to the open-source community, Spann’s output—measured in code commits, architectural blueprints, conference keynotes, and over fifty densely packed newsletters—charts the industry's migration from the "Modern Data Stack" to the "AI Data Cloud".1 This report provides an exhaustive, wrapped summary of his activities, analyzing the technical philosophies he espoused, the specific technologies he operationalized, and the community ecosystems he nurtured.

The narrative of Spann’s 2025 is one of integration. Where previous years might have been defined by the "wars" between batch and streaming, or between data warehouses and data lakes, Spann’s work in 2025 focused on the synthesis of these distinct paradigms into a unified "PINS" architecture (Polaris, Iceberg, NiFi, Snowflake). His work demonstrated that the rigors of high-throughput data engineering are the necessary substrate for the magic of Large Language Models (LLMs). Through a detailed examination of his "All Data and AI Weekly" publications, his GitHub repositories, and his public speaking engagements, we can discern a clear methodological progression: moving from data ingestion, to semantic understanding, and finally to agentic action.

### **1.1 The Professional Pivot: From Advocacy to Engineering**

While Spann has long been recognized as a Developer Advocate—having held principal roles at Cloudera, StreamNative, and Zilliz—his tenure at Snowflake in 2025 marked a subtle but significant shift toward "Solutions Engineering".2 This title change reflects a deeper industry trend: the move away from theoretical evangelism toward practical, deployable architectures. In 2025, the "Hello World" demo was no longer sufficient; the complexity of RAG (Retrieval-Augmented Generation) and Agentic workflows demanded robust, production-grade engineering.

Spann’s "Data In Motion" brand evolved to encompass this reality. The tagline, historically associated with Apache NiFi and Pulsar, expanded to include the static governance of Apache Polaris and the compute power of Snowflake Cortex. This duality—motion and rest, stream and lake—defined his architectural worldview in 2025\. He argued effectively that data is only "in motion" until it lands in a governed table format (Iceberg), at which point it becomes potential energy for AI models.4

### **1.2 The Core Thematic Pillars of 2025**

An analysis of the thousands of data points generated by Spann’s activities reveals four foundational pillars that supported his work throughout the year:

1. **The PINS AI Stack:** The crystallization of a reference architecture combining open standards (Polaris, Iceberg) with best-in-class ingestion (NiFi) and cloud compute (Snowflake).  
2. **Semantic Views & Context:** The realization that raw data schemas are insufficient for LLMs, necessitating a new "semantic layer" to bridge the gap between SQL and natural language.  
3. **The Democratization of Edge AI:** The use of accessible hardware (Raspberry Pi 5\) to prove that advanced computer vision and vector search can occur at the network edge, not just in the data center.  
4. **Agentic Workflows:** The transition from passive dashboards to active AI agents capable of reasoning, planning, and executing data tasks.

## **2\. The Architectural Pivot: From FLiP to PINS**

For several years, Timothy Spann was synonymous with the "FLiP" stack (Flink, Languages, Iceberg, Pulsar). This architecture was born out of the open-source streaming ecosystem, prioritizing low-latency event processing. However, 2025 saw the formal introduction and aggressive promotion of the "PINS" stack, a shift that mirrors the maturation of the enterprise data market.5

### **2.1 Deconstructing the PINS AI Stack**

The PINS stack represents a pragmatic compromise between the idealism of pure open source and the operational necessities of the enterprise.

* **P is for Polaris:** Apache Polaris emerged in 2025 as a critical component for metadata management. Spann identified early on that as data lakes grew into "Lakehouses," a vendor-neutral catalog was essential to prevent lock-in. His advocacy for Polaris centered on its ability to provide a unified view of data across different engines (Spark, Flink, Trino, Snowflake).6  
* **I is for Iceberg:** Apache Iceberg remained the immutable anchor of Spann’s architecture. In 2025, his focus shifted from "what is Iceberg?" to "how to optimize Iceberg." He produced content on distinct engineering challenges, such as compaction, snapshot management, and the performance implications of "Managed Iceberg Tables" within Snowflake.6  
* **N is for NiFi:** Despite the rise of new ingestion tools, Spann remained a steadfast champion of Apache NiFi. In 2025, he highlighted NiFi’s role not just as a mover of data, but as a "pre-processor" for AI—handling chunking, embedding generation, and PII redaction before the data ever hit the warehouse.7  
* **S is for Snowflake:** The inclusion of Snowflake (replacing the generic "Languages" or "Spark" of previous iterations) signaled an acknowledgment that for GenAI workloads, the elastic compute and integrated security of a data cloud are indispensable.3

| Component | FLiP Stack (Legacy) | PINS Stack (2025) | Architectural Implication |
| :---- | :---- | :---- | :---- |
| **Ingestion/Stream** | Apache Pulsar | Apache NiFi | Shift from pure pub/sub messaging to flow-based orchestration and transformation. |
| **Storage Format** | Apache Iceberg | Apache Iceberg | Continuity in the belief that open table formats are the future of storage. |
| **Catalog/Governance** | (Implicit/Hive) | Apache Polaris | Explicit focus on cross-platform governance and metadata interoperability. |
| **Compute/AI** | Apache Flink | Snowflake (Cortex) | Move toward managed, serverless compute optimized for Vector Search and LLMs. |

### **2.2 The Open Lakehouse Narrative**

A recurring theme in Spann’s 2025 writing was the "Open Lakehouse." In his April and May newsletters, he frequently referenced "Populating an Open Lakehouse with Codeless Data Streams".8 This narrative challenged the traditional data warehouse model where data must be loaded and converted into a proprietary format. Instead, Spann advocated for a model where data flows into an object store (S3/Azure Blob) in open formats (Parquet/Iceberg) and is immediately queryable.

This approach was particularly relevant for the unstructured data use cases he explored, such as air quality monitoring and transit tracking. By decoupling storage from compute, he demonstrated how organizations could build massive historical archives of sensor data without incurring prohibitive warehousing costs, spinning up Snowflake compute only when high-performance analytics or AI inference was required.

### **2.3 The Role of Apache NiFi 2.0**

2025 was a banner year for Apache NiFi, and Spann was at the forefront of its evangelism. The release of NiFi 2.0 introduced a feature that Spann had long clamored for: native Python processors. Previously, extending NiFi required Java development, a high barrier to entry for the data science community.

Spann’s presentation at "Community Over Code 2025," titled "Enhancing Apache NiFi 2.x with Python Processors," was a definitive technical deep dive into this capability.7 He demonstrated how developers could now drop standard Python scripts—using libraries like Pandas, Scikit-Learn, or LangChain—directly into the data flow. This effectively transformed NiFi from a data logistics tool into a distributed AI inference engine. He provided code examples of running sentiment analysis and image classification *in-stream*, allowing for real-time tagging and routing of data based on its content, not just its metadata.10

## **3\. The Snowflake Era: Engineering for the AI Data Cloud**

While Spann’s roots are in the Apache software foundation, his role as a Senior Solutions Engineer at Snowflake in 2025 placed him at the heart of the commercial AI revolution. His work during this period was characterized by a deep engagement with Snowflake’s emerging AI features, particularly Cortex AI and Snowpipe Streaming.

### **3.1 Cortex AI and the Democratization of Inference**

Snowflake Cortex AI, a fully managed service for LLMs and Vector Search, became a central tool in Spann’s repertoire. Throughout 2025, he published numerous guides on how to leverage Cortex for practical tasks, moving beyond the hype of chatbots.

* **Cortex Analyst:** In late 2025, Spann focused heavily on "Cortex Analyst," a tool designed to allow business users to query data using natural language. His work on "Optimizing Cortex Analyst Performance" 11 highlighted the nuance required to make these systems work; it wasn't magic, it required careful data modeling.  
* **Vector Search:** Spann integrated vector search into almost every project. Whether it was searching through transit logs or analyzing "paranormal" sensor data, he demonstrated how Snowflake could serve as a high-performance vector database, eliminating the need for separate, specialized infrastructure like Pinecone or Weaviate.12

### **3.2 Snowpipe Streaming and Dynamic Tables**

For a professional branded as "Data In Motion," Snowflake’s Snowpipe Streaming was a natural focal point. In 2025, Spann produced content detailing the architecture of "Next-Gen Snowpipe Streaming".11 He explained how this technology allowed for row-set based ingestion directly into Snowflake tables with sub-second latency, bypassing the traditional staging files approach.

He often paired Snowpipe Streaming with **Dynamic Tables**, Snowflake’s declarative transformation framework. This combination allowed him to build "streaming ETL" pipelines entirely within the Data Cloud. In his newsletter \#202, he discussed "Snowpipe Streaming High-Performance & Cost," offering a pragmatic look at the economics of real-time data, a topic often overlooked in technical tutorials.13

### **3.3 The "Zero to Snowflake" Education**

Spann’s contribution to the Snowflake ecosystem was also pedagogical. He served as an instructor for "Virtual Hands-On Labs," such as the "Zero to Snowflake" session in October 2025\.14 These sessions were critical for onboarding new users to the platform, covering the full gamut from data loading to advanced analytics. His teaching style, evidenced by his materials, prioritized "learning by doing," often forcing participants to troubleshoot common errors (e.g., "When your Kafka Sink Connector Writes Nothing" 15) rather than just following a "happy path" script.

## **4\. Semantic Views and the Cognitive Bridge**

Perhaps the most significant theoretical contribution Spann made in 2025 was the development and popularization of "Semantic Views." As the year progressed, it became clear that the primary bottleneck in Agentic AI was not model intelligence, but data context.

### **4.1 The Context Gap**

Spann identified a fundamental disconnect: Data engineers build schemas for efficiency (normalization, foreign keys, cryptic abbreviations), while AI agents require schemas for understanding (descriptive, denormalized, rich context). An LLM looking at a column named ts\_arr\_est might hallucinate its meaning; an LLM looking at a column named estimated\_arrival\_timestamp\_utc understands it instantly.

### **4.2 The Semantic View Solution**

In November 2025, Spann unveiled the "SemanticView" project, with repositories like SemanticViewBuilder, SemanticViewPlanes, and SemanticViewOzone.6 This work proposed a layer of abstraction where views are specifically engineered to serve as the "context window" for an AI model.

* **SemanticView for Traffic Events:** One of his flagship examples involved traffic data.16 He showed how to construct a view that joined geospatial coordinates with incident reports and weather data, wrapping the result in extensive SQL comments and metadata tags. This allowed an AI agent to answer complex queries like "Show me all accidents caused by rain in Princeton" without needing to understand the underlying table joins.  
* **Cursor AI Integration:** Interestingly, Spann highlighted the use of "Cursor AI" (an AI-powered code editor) to help automate the generation of these semantic views.6 This created a meta-narrative: using AI to build the infrastructure for AI.

### **4.3 The Model Context Protocol (MCP)**

Spann’s work on Semantic Views was tightly coupled with the "Model Context Protocol" (MCP), an open standard for connecting AI assistants to systems of record. In his late 2025 newsletters, particularly \#215 and \#216, he became a vocal proponent of MCP.16 He argued that MCP would become the standard interface for the "AI Data Cloud," allowing agents to securely discover and query data. He provided "hands-on labs" and "dev guides" for building general-purpose MCP servers that could translate natural language into SQL operations.16

## **5\. Unstructured Data and the "Dark Data" Frontier**

While 2024 was the year of text, 2025 for Spann was the year of multimodal data. He consistently argued that the vast majority of enterprise data is "dark"—locked away in images, PDFs, audio files, and sensor logs.

### **5.1 The "SnowGhostBreakers" Project**

In October 2025, just in time for Halloween, Spann released the "SnowGhostBreakers" project.16 While thematically playful, dealing with "Paranormal Data," the engineering underneath was serious. The project likely involved the ingestion of anomalous sensor readings (electromagnetic frequencies, thermal variations) and audio recordings.

Spann used this project to demonstrate **Cortex Code Demos** for handling unstructured data.4 He showed how to use Snowflake’s Python integration to run signal processing algorithms on the raw data, extract features, and then use Cortex AI to classify the signals. This project underscored the versatility of the modern data platform—capable of handling not just financial transactions, but signal intelligence.

### **5.2 Vision Agents and Image Processing**

A significant portion of Spann’s "unstructured" advocacy focused on computer vision. In his "All Data and AI Weekly" \#219, he referenced "Vision Agents".4 These agents were designed to analyze video streams—such as those from his Raspberry Pi cameras—and generate textual descriptions of the scene.

This capability was demonstrated in his "TrafficAI" work, where traffic camera feeds were ingested, processed to identify vehicle counts and types, and the resulting structured data was stored in Snowflake for analysis. This workflow—**Video \-\> Inference \-\> Structured Data \-\> SQL**—represents the holy grail of physical operations analytics, and Spann provided a blueprint for achieving it using commodity hardware and cloud services.

### **5.3 Vector Databases: Milvus and Zilliz**

Spann’s previous role at Zilliz continued to influence his 2025 work. He frequently discussed the importance of Vector Databases like Milvus for handling the embeddings generated from unstructured data.17 His talks at PyData NYC emphasized that a vector database is not just a search engine, but a "long-term memory" for AI agents, allowing them to recall similar images or documents from the past to inform current decisions.

## **6\. Edge AI: Computing at the Fringe**

For Timothy Spann, the "Data Cloud" did not exist in isolation; it was fed by the "Edge." throughout 2025, he maintained a robust stream of projects focused on the Raspberry Pi ecosystem, proving that modern AI architectures must span from the sensor to the snowflake.

### **6.1 Raspberry Pi 5 and the AI Kit**

The release of the Raspberry Pi 5 and its associated AI Kit (likely the Hailo-8 or similar accelerator) was a catalyst for Spann’s 2025 edge projects. He published tutorials on "Unstructured Data Processing with a Raspberry Pi AI Kit and Python".17 He demonstrated that these small, low-power devices were now capable of running object detection (YOLO models) and pose estimation in real-time.

### **6.2 The Thermal Streaming Project**

A standout project in December 2025 was the "RPi Thermal Streaming" system.4 This involved connecting thermal cameras to a Raspberry Pi to monitor heat signatures—a use case relevant for industrial IoT (preventative maintenance) and security.

The engineering challenge here was bandwidth and latency. Spann demonstrated how to process the thermal array locally on the Pi, convert the raw temperature data into a color-mapped image, and stream both the image and the raw telemetry to the cloud via Kafka/Redpanda. The "Massive Performance Updates" he touted in late 2025 likely involved optimizing the Python code to utilize the Pi’s multi-core architecture or the AI accelerator, reducing latency to near-real-time levels.4

### **6.3 ADSB and Aviation Tracking**

Another recurring edge data source was ADSB (Automatic Dependent Surveillance–Broadcast), the technology used to track aircraft. Spann released documentation and code for ingesting ADSB data into Snowflake.4 This use case is a classic "Big Data" problem: high velocity, high volume, and geospatial complexity. Spann used it to showcase the power of **Cortex AI SQL**, demonstrating how to write SQL queries that could predict flight paths or detect anomalies in airspace, effectively democratizing air traffic control analytics.

## **7\. The Chronicle of 2025: Analysis of "All Data and AI Weekly"**

The backbone of Spann’s public output was his newsletter, "All Data and AI Weekly" (formerly FLiP Stack Weekly). A chronological analysis of these newsletters reveals the industry's pulse week by week.

### **7.1 Q1 2025: Foundations and Integration (Jan \- March)**

* **Themes:** The year began with a focus on the basics of the "Modern Data Stack." Issues \#176 through \#180 18 covered topics like connecting Kafka to Snowflake, the fundamentals of Apache Iceberg, and early experiments with GenAI.  
* **Key Insight:** During this period, Spann was laying the groundwork. He emphasized "Integration"—ensuring that the pipes (NiFi, Kafka) were robust enough to handle the coming wave of AI workloads. The transition from "FLiP Stack" to "Data and AI Weekly" likely occurred or solidified in this quarter, reflecting the rebranding of the industry.

### **7.2 Q2 2025: Unstructured Data and Lakehouses (April \- June)**

* **Themes:** As the weather warmed, so did the focus on "Dark Data." Issues \#186 (April 21\) through \#195 (June 23\) 19 were dominated by unstructured data workflows. This coincided with his preparations for the Data Summit in Boston.  
* **Key Projects:** This period saw the release of articles on "Populating an Open Lakehouse with Codeless Data Streams" 8 and "Real-Time Enrichment of Air Quality Data." The focus was on *getting data in*—taking messy, real-world signals and landing them in the Lakehouse.  
* **Events:** The "Hex \+ Snowflake Hackathon" in NYC 21 highlighted his commitment to getting hands-on with the community, exploring new tools like Hex for collaborative data science.

### **7.3 Q3 2025: Governance and Operations (July \- September)**

* **Themes:** With the ingestion patterns established, the conversation shifted to management. Issues \#198 through \#208 22 featured content on **Apache Polaris** (governance) and **Snowpipe Streaming** monitoring.  
* **Key Insight:** The "open catalog" wars were in full swing, and Spann advocated for Polaris as the Switzerland of metadata. He also addressed the operational side of streaming, writing about "OpenFlow Monitoring" and "Lifecycle Policies" to manage storage costs.24 This showed a mature engineering mindset—it's not enough to build the pipeline; you have to afford the bill.

### **7.4 Q4 2025: The Agentic Explosion (October \- December)**

* **Themes:** The final quarter was a sprint toward **Agentic AI**. Issues \#213 through \#219 6 were laser-focused on Cortex Agents, MCP, and Semantic Views.  
* **Key Innovation:** This is when the "Semantic View" concept crystallized. The rhetoric shifted from "How do I query this?" to "How does my agent understand this?" The year ended with a strong push on **Snowflake Intelligence**, positioning it as the brain that sits atop the data body he had spent the year building.

| Period | Newsletter IDs | Dominant Theme | Key Technologies |
| :---- | :---- | :---- | :---- |
| **Q1** | \#170 \- \#180 | Foundation & Integration | Kafka, Iceberg, Basic RAG |
| **Q2** | \#184 \- \#196 | Unstructured Data | NiFi 2.0, OpenAQ, GTFS |
| **Q3** | \#198 \- \#210 | Governance & Ops | Apache Polaris, OpenFlow, Snowpipe |
| **Q4** | \#211 \- \#219 | Agentic AI & Semantics | Cortex Agents, MCP, Semantic Views |

## **8\. Public Speaking and Community Evangelism**

Timothy Spann’s 2025 schedule was a tour de force of technical public speaking. He did not merely present slides; he built labs, ran hackathons, and conducted live coding sessions.

### **8.1 Snowflake BUILD 2025 (November 4-6)**

At Snowflake’s flagship developer conference, Spann was a critical asset. He moved beyond high-level marketing to deliver technical enablement.

* **Hands-On Labs:** He led the "Zero to Snowflake" and "Build and Deploy Data Agents" labs.14 These sessions are high-pressure environments where the instructor must troubleshoot live issues for hundreds of attendees. His success here cemented his reputation as a "teacher-practitioner."  
* **MCP Evangelism:** He used this stage to debut his work on the Model Context Protocol, explaining to a global audience why standardizing agent interfaces is crucial for the industry.

### **8.2 Community Over Code NA 2025 (September 12\)**

Held in Minneapolis, this event (formerly ApacheCon) is the spiritual home of the open-source community. Spann delivered three distinct talks, showcasing his versatility.7

1. **"NiFi Man: We're Here, But Should We Have Come?"** This talk was a philosophical retrospective. It explored the architectural decision-making process—when to use NiFi, and more importantly, when *not* to. It addressed the "resume-driven development" trap, advising peers to choose the right tool for the job, even if it's boring.  
2. **"Utilizing Real-Time Transit Data for Travel Optimization"**: A practical application talk, demonstrating the GTFS use case.  
3. **"Enhancing Apache NiFi 2.x with Python"**: A hard-technical talk on the new features of NiFi 2.0.

### **8.3 Data Summit 2025 (Boston, May 14\)**

Spann’s presentation "AI Meets Unstructured Data" 26 addressed the business audience. He articulated the value proposition of unlocking "dark data," moving the conversation from "cool tech" to "ROI." He argued that the competitive advantage of the next decade lies in mining the 80% of data that currently sits dormant in object storage.

### **8.4 Grassroots Community Building**

Despite his global stage, Spann remained committed to the local meetup scene.

* **Future of Data Meetups:** He continued to run groups in Princeton, NYC, and Philadelphia.1 These smaller, intimate venues allowed him to test "beta" versions of his talks and gather unfiltered feedback from developers.  
* **Collaboration:** He actively promoted the work of others, frequently spotlighting community members like Tsubasa Kanno and Ashutosh in his newsletters 18, fostering a sense of shared success.

## **9\. Conclusion: The Autonomous Future**

The retrospective of Timothy Spann’s 2025 reveals a clear trajectory for the data engineering profession. He began the year building pipelines to move data; he ended the year building semantic layers to explain data to machines.

Spann’s work demonstrates that **Agentic AI is an infrastructure problem.** You cannot have autonomous agents without:

1. **Real-time ingestion** (NiFi/Snowpipe) to provide current state.  
2. **Open governance** (Polaris/Iceberg) to ensure safety and access.  
3. **Semantic context** (Semantic Views/MCP) to prevent hallucinations.  
4. **Edge intelligence** (Raspberry Pi/Sensor networks) to capture physical reality.

By systematically addressing each of these layers throughout 2025, Timothy Spann did not just observe the future of data; he engineered it. His "PINS" stack provides the blueprint for the "Autonomous Enterprise," and his extensive library of tutorials, repositories, and newsletters ensures that the community has the roadmap to follow him there. As the industry looks toward 2026, Spann’s focus on the "Context Layer" suggests that the next frontier will not be about faster models, but about smarter data.

#### **Works cited**

1. Timothy Spann \- All Things Open 2024, accessed December 15, 2025, [https://2024.allthingsopen.org/speakers/timothy-spann](https://2024.allthingsopen.org/speakers/timothy-spann)  
2. Tim Spann \- DZone Expert, accessed December 15, 2025, [https://dzone.com/authors/bunkertor](https://dzone.com/authors/bunkertor)  
3. tspannhw (Timothy Spann) · GitHub, accessed December 15, 2025, [https://github.com/tspannhw](https://github.com/tspannhw)  
4. Data In Motion, accessed December 15, 2025, [https://datainmotion.dev/](https://datainmotion.dev/)  
5. Timothy Spann's Speaker Profile \- Sessionize, accessed December 15, 2025, [https://sessionize.com/tspann/](https://sessionize.com/tspann/)  
6. All Data and AI Weekly \#216 17-Nov-2025 | by Tim Spann \- Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-216-17-nov-2025-25703567baa9](https://medium.com/@tspann/all-data-and-ai-weekly-216-17-nov-2025-25703567baa9)  
7. All Data and AI Weekly \#207: 15 Sept 2025 | by Tim Spann \- Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-207-15-sept-2025-20b6a9f261be](https://medium.com/@tspann/all-data-and-ai-weekly-207-15-sept-2025-20b6a9f261be)  
8. Tim Spann – Medium, accessed December 15, 2025, [https://medium.com/@tspann](https://medium.com/@tspann)  
9. All Data and AI Weekly \#188 \- May 5, 2025, accessed December 15, 2025, [https://www.datainmotion.dev/2025/05/all-data-and-ai-weekly-188-may-5-2025.html](https://www.datainmotion.dev/2025/05/all-data-and-ai-weekly-188-may-5-2025.html)  
10. FLaNK AI / KNIFe AI Weekly 25 March 2025 | by Tim Spann | Medium, accessed December 15, 2025, [https://medium.com/@tspann/flank-ai-knife-ai-weekly-25-march-2025-6a615656a69b](https://medium.com/@tspann/flank-ai-knife-ai-weekly-25-march-2025-6a615656a69b)  
11. All Data and AI Weekly \#217–24Nov2025 | by Tim Spann | Nov, 2025 | Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-217-24nov2025-348f5aff687c](https://medium.com/@tspann/all-data-and-ai-weekly-217-24nov2025-348f5aff687c)  
12. What's in the Air Tonight Mr. Milvus? | by Tim Spann \- Medium, accessed December 15, 2025, [https://medium.com/@tspann/whats-in-the-air-tonight-mr-milvus-fbd42f06e482](https://medium.com/@tspann/whats-in-the-air-tonight-mr-milvus-fbd42f06e482)  
13. All Data and AI Weekly \#202 11-Aug-2025 | by Tim Spann | Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-202-11-aug-2025-e3014129a0a5](https://medium.com/@tspann/all-data-and-ai-weekly-202-11-aug-2025-e3014129a0a5)  
14. eeAll Data and AI Weekly \#211: 13 Oct 2025 | by Tim Spann \- Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-211-13-oct-2025-e506fbaf28a9](https://medium.com/@tspann/all-data-and-ai-weekly-211-13-oct-2025-e506fbaf28a9)  
15. All Data and AI Weekly \#202 11-Aug-2025 \- DEV Community, accessed December 15, 2025, [https://dev.to/timothy\_spann\_a41a639e47c/all-data-and-ai-weekly-202-11-aug-2025-6g3](https://dev.to/timothy_spann_a41a639e47c/all-data-and-ai-weekly-202-11-aug-2025-6g3)  
16. All Data and AI Weekly \#216:17Nov2025 \- DEV Community, accessed December 15, 2025, [https://dev.to/timothy\_spann\_a41a639e47c/all-data-and-ai-weekly-21617nov2025-2hl1](https://dev.to/timothy_spann_a41a639e47c/all-data-and-ai-weekly-21617nov2025-2hl1)  
17. Timothy Spann :: PyData NYC 2024, accessed December 15, 2025, [https://pydata.org/nyc2024/schedule/speaker/C77WUG/](https://pydata.org/nyc2024/schedule/speaker/C77WUG/)  
18. Snowflake Page 4 \- Forem, accessed December 15, 2025, [https://forem.com/t/snowflake/page/4](https://forem.com/t/snowflake/page/4)  
19. All Data and AI Weekly \#186 — April 21, 2025 \- DEV Community, accessed December 15, 2025, [https://dev.to/timothy\_spann\_a41a639e47c/all-data-and-ai-weekly-186-april-21-2025-2opi](https://dev.to/timothy_spann_a41a639e47c/all-data-and-ai-weekly-186-april-21-2025-2opi)  
20. All Data and AI Weekly \#195 — June 23, 2025 | by Tim Spann | Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-195-june-23-2025-d43bb630204e](https://medium.com/@tspann/all-data-and-ai-weekly-195-june-23-2025-d43bb630204e)  
21. All Data and AI Weekly \#196 — June 30, 2025 | by Tim Spann | Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-196-june-30-2025-39800deefb70](https://medium.com/@tspann/all-data-and-ai-weekly-196-june-30-2025-39800deefb70)  
22. All Data and AI Weekly \#198 — July 14, 2025 | by Tim Spann | Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-198-july-14-2025-2f6fb7e498bb](https://medium.com/@tspann/all-data-and-ai-weekly-198-july-14-2025-2f6fb7e498bb)  
23. All Data and AI Weekly \#198 \- July 14, 2025 \- DEV Community, accessed December 15, 2025, [https://dev.to/timothy\_spann\_a41a639e47c/all-data-and-ai-weekly-198-july-14-2025-2bf2](https://dev.to/timothy_spann_a41a639e47c/all-data-and-ai-weekly-198-july-14-2025-2bf2)  
24. All Data and AI Weekly \#191 — May 26, 2025 | by Tim Spann \- Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-191-may-26-2025-ec5e4bc95057](https://medium.com/@tspann/all-data-and-ai-weekly-191-may-26-2025-ec5e4bc95057)  
25. All Data and AI Weekly \#215: 10 November 2025 | by Tim Spann \- Medium, accessed December 15, 2025, [https://medium.com/@tspann/all-data-and-ai-weekly-215-10-november-2025-5b4c25db43eb](https://medium.com/@tspann/all-data-and-ai-weekly-215-10-november-2025-5b4c25db43eb)  
26. Data Summit Conference, accessed December 15, 2025, [https://www.dbta.com/DataSummit/2024/Timothy-Spann.aspx](https://www.dbta.com/DataSummit/2024/Timothy-Spann.aspx)
